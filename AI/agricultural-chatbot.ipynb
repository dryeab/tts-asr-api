{"cells":[{"cell_type":"markdown","metadata":{"id":"6xoKYBBO6xaV"},"source":["# **Chatbot using Seq2Seq LSTM models**"]},{"cell_type":"markdown","metadata":{"id":"2SOmE99B7Is0"},"source":["This project is to create conversational chatbot using Sequence to sequence LSTM models.\n","Sequence to sequence learning is about training models to convert from one domain to sequences another domain."]},{"cell_type":"markdown","metadata":{"id":"mVuZTAV08qWY"},"source":["# Step 1: Import all the packages"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-06-11T15:03:35.226885Z","iopub.status.busy":"2024-06-11T15:03:35.226381Z","iopub.status.idle":"2024-06-11T15:03:58.871107Z","shell.execute_reply":"2024-06-11T15:03:58.869261Z","shell.execute_reply.started":"2024-06-11T15:03:35.226836Z"},"id":"U0mJXRse83hp","trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["2024-06-11 15:03:38.662603: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-06-11 15:03:38.662895: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-06-11 15:03:38.913922: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"]}],"source":["import numpy as np\n","import tensorflow as tf\n","import pickle\n","from tensorflow.keras import layers, activations, models, preprocessing"]},{"cell_type":"markdown","metadata":{"id":"l4kJp6uO-fQE"},"source":["# Step 3: Preprocessing the data"]},{"cell_type":"markdown","metadata":{"id":"QEV_hSXs-7mF"},"source":["### a) Reading the data from the files\n","We parse each of the .yaml files.\n","\n","1. Concatenate two or more sentences if the answer has two or more of them.\n","2. Remove unwanted data types which are produced while parsing the data.\n","3. Append <START> and <END> to all the answers.\n","4. Create a Tokenizer and load the whole vocabulary ( questions + answers ) into it."]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-06-11T15:04:10.962864Z","iopub.status.busy":"2024-06-11T15:04:10.962417Z","iopub.status.idle":"2024-06-11T15:04:10.971369Z","shell.execute_reply":"2024-06-11T15:04:10.968608Z","shell.execute_reply.started":"2024-06-11T15:04:10.962830Z"},"id":"kWYOjzOc_iQi","trusted":true},"outputs":[],"source":["from tensorflow.keras import preprocessing, utils\n","import os\n","import yaml"]},{"cell_type":"markdown","metadata":{"id":"qyUnopqjDjud"},"source":["The dataset contains .yml files which have pairs of different questions and their answers on varied subjects like history, bot profile, science etc.\n","We can easily read them as folows:"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-06-11T15:04:12.692696Z","iopub.status.busy":"2024-06-11T15:04:12.691420Z","iopub.status.idle":"2024-06-11T15:04:12.702393Z","shell.execute_reply":"2024-06-11T15:04:12.699787Z","shell.execute_reply.started":"2024-06-11T15:04:12.692620Z"},"id":"RxG-s4k0CowI","trusted":true},"outputs":[],"source":["file_path = 'data/agri_questions_and_answers_2000_et.yml'"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2024-06-11T15:04:14.997914Z","iopub.status.busy":"2024-06-11T15:04:14.997408Z","iopub.status.idle":"2024-06-11T15:04:16.090193Z","shell.execute_reply":"2024-06-11T15:04:16.088396Z","shell.execute_reply.started":"2024-06-11T15:04:14.997874Z"},"id":"-bRvbQ00Coy5","outputId":"c641166b-aaee-464b-fa40-165badf194c2","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["['የሙዝ ሰብል የመጣው ከየት ነው?', 'በደቡብ ምስራቅ እስያ የሙዝ ሰብል ምን ያህል ጊዜ ይመረታል?']\n","['<START> ደቡብ ምስራቅ እስያ <END>', '<START> በሺዎች የሚቆጠሩ ዓመታት <END>']\n","VOCAB SIZE : 5961\n"]}],"source":["questions = list()\n","answers = list()\n","\n","stream = open( file_path, 'rb')\n","docs = yaml.safe_load(stream)\n","conversations = docs['conversations']\n","for con in conversations:\n","    if len( con ) > 2 :\n","        questions.append(con[0])\n","        replies = con[ 1 : ]\n","        ans = ''\n","        for rep in replies:\n","            ans += ' ' + rep\n","        answers.append( ans )\n","    elif len( con )> 1:\n","        questions.append(con[0])\n","        answers.append(con[1])\n","\n","answers_with_tags = list()\n","for i in range( len( answers ) ):\n","    if type( answers[i] ) == str:\n","        answers_with_tags.append( answers[i] )\n","    else:\n","        questions.pop( i )\n","\n","answers = list()\n","for i in range( len( answers_with_tags ) ) :\n","    answers.append( '<START> ' + answers_with_tags[i] + ' <END>' )\n","\n","tokenizer = preprocessing.text.Tokenizer()\n","tokenizer.fit_on_texts( questions + answers )\n","VOCAB_SIZE = len( tokenizer.word_index )+1\n","\n","print(questions[:2])\n","print(answers[:2])\n","print( 'VOCAB SIZE : {}'.format( VOCAB_SIZE ))"]},{"cell_type":"markdown","metadata":{"id":"WMPqb8LxIeGI"},"source":["### b) Preparing data for Seq2Seq model\n","\n","This model requires 3 arrays encoder_input_data, decoder_input_data and decoder_output_data.\n","\n","For encoder_input_data:\n","Tokensize the Questions and Pad them to their maximum Length.\n","\n","For decoder_input_data:\n","Tokensize the Answers and Pad them to their maximum Length.\n","\n","For decoder_output_data:\n","Tokensize the Answers and Remove the 1st element from all the tokenized_answers. This is the <START> element which was added earlier."]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-06-11T15:04:25.635443Z","iopub.status.busy":"2024-06-11T15:04:25.633942Z","iopub.status.idle":"2024-06-11T15:04:59.374212Z","shell.execute_reply":"2024-06-11T15:04:59.372818Z","shell.execute_reply.started":"2024-06-11T15:04:25.635380Z"},"id":"oEfAPL4HCo1t","trusted":true},"outputs":[],"source":["from gensim.models import Word2Vec\n","import re"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-06-11T15:04:59.377283Z","iopub.status.busy":"2024-06-11T15:04:59.376321Z","iopub.status.idle":"2024-06-11T15:04:59.387555Z","shell.execute_reply":"2024-06-11T15:04:59.385745Z","shell.execute_reply.started":"2024-06-11T15:04:59.377240Z"},"id":"QqYoDsbSCo4f","trusted":true},"outputs":[],"source":["vocab = []\n","for word in tokenizer.word_index:\n","  vocab.append(word)\n","\n","def tokenize(sentences):\n","  tokens_list = []\n","  vocabulary = []\n","  for sentence in sentences:\n","    sentence = sentence.lower()\n","    sentence = re.sub('[^a-zA-Z]', ' ', sentence)\n","    tokens = sentence.split()\n","    vocabulary += tokens\n","    tokens_list.append(tokens)\n","  return tokens_list, vocabulary"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2024-06-11T15:05:02.598453Z","iopub.status.busy":"2024-06-11T15:05:02.598044Z","iopub.status.idle":"2024-06-11T15:05:02.668240Z","shell.execute_reply":"2024-06-11T15:05:02.665950Z","shell.execute_reply.started":"2024-06-11T15:05:02.598424Z"},"id":"9vKhieIwCo7J","outputId":"446ca007-7838-41e7-f448-2ee0d7904566","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["(1831, 18) 18\n"]}],"source":["#encoder_input_data\n","tokenized_questions = tokenizer.texts_to_sequences( questions )\n","maxlen_questions = max( [len(x) for x in tokenized_questions ] )\n","padded_questions = preprocessing.sequence.pad_sequences( tokenized_questions, maxlen = maxlen_questions, padding = 'post')\n","encoder_input_data = np.array(padded_questions)\n","print(encoder_input_data.shape, maxlen_questions)"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2024-06-11T15:05:03.882089Z","iopub.status.busy":"2024-06-11T15:05:03.879794Z","iopub.status.idle":"2024-06-11T15:05:03.973680Z","shell.execute_reply":"2024-06-11T15:05:03.971329Z","shell.execute_reply.started":"2024-06-11T15:05:03.882024Z"},"id":"AJo7WPjLCo-q","outputId":"ad315730-7290-4a70-9b7b-b8911ff87264","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["(1831, 120) 120\n"]}],"source":["# decoder_input_data\n","tokenized_answers = tokenizer.texts_to_sequences( answers )\n","maxlen_answers = max( [ len(x) for x in tokenized_answers ] )\n","padded_answers = preprocessing.sequence.pad_sequences( tokenized_answers , maxlen=maxlen_answers , padding='post' )\n","decoder_input_data = np.array( padded_answers )\n","print( decoder_input_data.shape , maxlen_answers )"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-06-11T15:05:05.040941Z","iopub.status.busy":"2024-06-11T15:05:05.040486Z","iopub.status.idle":"2024-06-11T15:05:17.087577Z","shell.execute_reply":"2024-06-11T15:05:17.085146Z","shell.execute_reply.started":"2024-06-11T15:05:05.040908Z"},"id":"ccY0wWdRCpCa","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["(1831, 120, 5961)\n"]}],"source":["# decoder_output_data\n","tokenized_answers = tokenizer.texts_to_sequences( answers )\n","for i in range(len(tokenized_answers)) :\n","    tokenized_answers[i] = tokenized_answers[i][1:]\n","padded_answers = preprocessing.sequence.pad_sequences( tokenized_answers , maxlen=maxlen_answers , padding='post' )\n","onehot_answers = utils.to_categorical( padded_answers , VOCAB_SIZE )\n","decoder_output_data = np.array( onehot_answers )\n","print( decoder_output_data.shape )"]},{"cell_type":"markdown","metadata":{"id":"-D53pyucPCnk"},"source":["# Step 4: Defining Encoder Decoder Model\n","\n","\n","\n"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2024-06-11T15:05:28.249156Z","iopub.status.busy":"2024-06-11T15:05:28.246942Z","iopub.status.idle":"2024-06-11T15:05:28.607743Z","shell.execute_reply":"2024-06-11T15:05:28.605445Z","shell.execute_reply.started":"2024-06-11T15:05:28.249071Z"},"id":"W3YjCFDwPRVN","outputId":"cdbcd5e9-a1df-4d76-80a0-0dafadfc1da6","trusted":true},"outputs":[{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n","</pre>\n"],"text/plain":["\u001b[1mModel: \"functional_1\"\u001b[0m\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n","┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n","┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n","│ input_layer         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ input_layer_1       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ embedding           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)   │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,192,200</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ not_equal           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">NotEqual</span>)          │                   │            │                   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ embedding_1         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)  │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,192,200</span> │ input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)         │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>),     │    <span style=\"color: #00af00; text-decoration-color: #00af00\">320,800</span> │ embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n","│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>),      │            │ not_equal[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n","│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)]      │            │                   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>,      │    <span style=\"color: #00af00; text-decoration-color: #00af00\">320,800</span> │ embedding_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n","│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │            │ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>],       │\n","│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │            │ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>]        │\n","│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)]             │            │                   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5961</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,198,161</span> │ lstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n","└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n","</pre>\n"],"text/plain":["┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n","┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n","┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n","│ input_layer         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n","│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ input_layer_1       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m120\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ -                 │\n","│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ embedding           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m, \u001b[38;5;34m200\u001b[0m)   │  \u001b[38;5;34m1,192,200\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n","│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ not_equal           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n","│ (\u001b[38;5;33mNotEqual\u001b[0m)          │                   │            │                   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ embedding_1         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m120\u001b[0m, \u001b[38;5;34m200\u001b[0m)  │  \u001b[38;5;34m1,192,200\u001b[0m │ input_layer_1[\u001b[38;5;34m0\u001b[0m]… │\n","│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ lstm (\u001b[38;5;33mLSTM\u001b[0m)         │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m),     │    \u001b[38;5;34m320,800\u001b[0m │ embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n","│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m),      │            │ not_equal[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n","│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)]      │            │                   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)       │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m120\u001b[0m,      │    \u001b[38;5;34m320,800\u001b[0m │ embedding_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n","│                     │ \u001b[38;5;34m200\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,      │            │ lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m1\u001b[0m],       │\n","│                     │ \u001b[38;5;34m200\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,      │            │ lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m2\u001b[0m]        │\n","│                     │ \u001b[38;5;34m200\u001b[0m)]             │            │                   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ dense (\u001b[38;5;33mDense\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m120\u001b[0m, \u001b[38;5;34m5961\u001b[0m) │  \u001b[38;5;34m1,198,161\u001b[0m │ lstm_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n","└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,224,161</span> (16.11 MB)\n","</pre>\n"],"text/plain":["\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,224,161\u001b[0m (16.11 MB)\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,224,161</span> (16.11 MB)\n","</pre>\n"],"text/plain":["\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m4,224,161\u001b[0m (16.11 MB)\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n","</pre>\n"],"text/plain":["\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"]},"metadata":{},"output_type":"display_data"}],"source":["encoder_inputs = tf.keras.layers.Input(shape=( maxlen_questions , ))\n","encoder_embedding = tf.keras.layers.Embedding( VOCAB_SIZE, 200 , mask_zero=True ) (encoder_inputs)\n","encoder_outputs , state_h , state_c = tf.keras.layers.LSTM( 200 , return_state=True )( encoder_embedding )\n","encoder_states = [ state_h , state_c ]\n","\n","decoder_inputs = tf.keras.layers.Input(shape=( maxlen_answers ,  ))\n","decoder_embedding = tf.keras.layers.Embedding( VOCAB_SIZE, 200 , mask_zero=True) (decoder_inputs)\n","decoder_lstm = tf.keras.layers.LSTM( 200 , return_state=True , return_sequences=True )\n","decoder_outputs , _ , _ = decoder_lstm ( decoder_embedding , initial_state=encoder_states )\n","decoder_dense = tf.keras.layers.Dense( VOCAB_SIZE , activation=tf.keras.activations.softmax )\n","output = decoder_dense ( decoder_outputs )\n","\n","model = tf.keras.models.Model([encoder_inputs, decoder_inputs], output )\n","model.compile(optimizer=tf.keras.optimizers.RMSprop(), loss='categorical_crossentropy')\n","\n","model.summary()"]},{"cell_type":"markdown","metadata":{"id":"wVfSormAPb3w"},"source":["# Step 5: Training the Model\n","\n","We train the model for a number of epochs with RMSprop optimizer and categorical_crossentropy loss function."]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-06-11T15:06:12.786072Z","iopub.status.busy":"2024-06-11T15:06:12.785622Z","iopub.status.idle":"2024-06-11T15:06:12.799392Z","shell.execute_reply":"2024-06-11T15:06:12.796439Z","shell.execute_reply.started":"2024-06-11T15:06:12.786035Z"},"trusted":true},"outputs":[],"source":["from keras.callbacks import ModelCheckpoint\n","\n","filepath = 'saved_weights_for_words/saved_weights-{epoch:02d}-{loss:.4f}.keras'\n","checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True)\n","\n","callbacks_list = [checkpoint]"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2024-06-11T15:06:14.278363Z","iopub.status.busy":"2024-06-11T15:06:14.277815Z","iopub.status.idle":"2024-06-11T17:00:35.853124Z","shell.execute_reply":"2024-06-11T17:00:35.851406Z","shell.execute_reply.started":"2024-06-11T15:06:14.278320Z"},"id":"OHlqQq64PYTH","outputId":"dd99206b-b604-4b51-9d2a-2f673a29de40","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/150\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 8.4447\n","Epoch 1: loss improved from inf to 7.90115, saving model to saved_weights_for_words/saved_weights-01-7.9012.keras\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 1s/step - loss: 8.4304\n","Epoch 2/150\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 6.8065\n","Epoch 2: loss improved from 7.90115 to 6.80768, saving model to saved_weights_for_words/saved_weights-02-6.8077.keras\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 1s/step - loss: 6.8065\n","Epoch 3/150\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 6.7197\n","Epoch 3: loss improved from 6.80768 to 6.71766, saving model to saved_weights_for_words/saved_weights-03-6.7177.keras\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 1s/step - loss: 6.7196\n","Epoch 4/150\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 6.6199\n","Epoch 4: loss improved from 6.71766 to 6.62685, saving model to saved_weights_for_words/saved_weights-04-6.6269.keras\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 1s/step - loss: 6.6201\n","Epoch 5/150\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 6.4856\n","Epoch 5: loss improved from 6.62685 to 6.47868, saving model to saved_weights_for_words/saved_weights-05-6.4787.keras\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 1s/step - loss: 6.4855\n","Epoch 6/150\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 6.3915\n","Epoch 6: loss improved from 6.47868 to 6.37269, saving model to saved_weights_for_words/saved_weights-06-6.3727.keras\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 1s/step - loss: 6.3910\n","Epoch 7/150\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 6.3343\n","Epoch 7: loss improved from 6.37269 to 6.32281, saving model to saved_weights_for_words/saved_weights-07-6.3228.keras\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 1s/step - loss: 6.3340\n","Epoch 8/150\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 6.2984\n","Epoch 8: loss improved from 6.32281 to 6.29591, saving model to saved_weights_for_words/saved_weights-08-6.2959.keras\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 1s/step - loss: 6.2984\n","Epoch 9/150\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 6.2367\n","Epoch 9: loss improved from 6.29591 to 6.26851, saving model to saved_weights_for_words/saved_weights-09-6.2685.keras\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 1s/step - loss: 6.2376\n","Epoch 10/150\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 6.2221\n","Epoch 10: loss improved from 6.26851 to 6.24261, saving model to saved_weights_for_words/saved_weights-10-6.2426.keras\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 1s/step - loss: 6.2226\n","Epoch 11/150\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 6.1969\n","Epoch 11: loss improved from 6.24261 to 6.21586, saving model to saved_weights_for_words/saved_weights-11-6.2159.keras\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 1s/step - loss: 6.1974\n","Epoch 12/150\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 6.2065\n","Epoch 12: loss improved from 6.21586 to 6.19464, saving model to saved_weights_for_words/saved_weights-12-6.1946.keras\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 1s/step - loss: 6.2062\n","Epoch 13/150\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 6.1697\n","Epoch 13: loss improved from 6.19464 to 6.16934, saving model to saved_weights_for_words/saved_weights-13-6.1693.keras\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 1s/step - loss: 6.1697\n","Epoch 14/150\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 6.1287\n","Epoch 14: loss improved from 6.16934 to 6.13891, saving model to saved_weights_for_words/saved_weights-14-6.1389.keras\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 1s/step - loss: 6.1289\n","Epoch 15/150\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - loss: 6.1053\n","Epoch 15: loss improved from 6.13891 to 6.11002, saving model to saved_weights_for_words/saved_weights-15-6.1100.keras\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 2s/step - loss: 6.1054\n","Epoch 16/150\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 6.0932\n","Epoch 16: loss improved from 6.11002 to 6.07334, saving model to saved_weights_for_words/saved_weights-16-6.0733.keras\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 1s/step - loss: 6.0927\n","Epoch 17/150\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 6.0172\n","Epoch 17: loss improved from 6.07334 to 6.04582, saving model to saved_weights_for_words/saved_weights-17-6.0458.keras\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 1s/step - loss: 6.0180\n","Epoch 18/150\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 6.0138\n","Epoch 18: loss improved from 6.04582 to 6.01082, saving model to saved_weights_for_words/saved_weights-18-6.0108.keras\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 1s/step - loss: 6.0138\n","Epoch 19/150\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 5.9944\n","Epoch 19: loss improved from 6.01082 to 5.98278, saving model to saved_weights_for_words/saved_weights-19-5.9828.keras\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 1s/step - loss: 5.9941\n","Epoch 20/150\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 5.8941\n","Epoch 20: loss improved from 5.98278 to 5.94265, saving model to saved_weights_for_words/saved_weights-20-5.9426.keras\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 1s/step - loss: 5.8953\n","Epoch 21/150\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 5.9038\n","Epoch 21: loss improved from 5.94265 to 5.90346, saving model to saved_weights_for_words/saved_weights-21-5.9035.keras\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 1s/step - loss: 5.9038\n","Epoch 22/150\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 5.8438\n","Epoch 22: loss improved from 5.90346 to 5.85743, saving model to saved_weights_for_words/saved_weights-22-5.8574.keras\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 1s/step - loss: 5.8442\n","Epoch 23/150\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 5.7941\n","Epoch 23: loss improved from 5.85743 to 5.81982, saving model to saved_weights_for_words/saved_weights-23-5.8198.keras\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 1s/step - loss: 5.7948\n","Epoch 24/150\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 5.7054\n","Epoch 24: loss improved from 5.81982 to 5.77230, saving model to saved_weights_for_words/saved_weights-24-5.7723.keras\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 1s/step - loss: 5.7072\n","Epoch 25/150\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 5.7149\n","Epoch 25: loss improved from 5.77230 to 5.73473, saving model to saved_weights_for_words/saved_weights-25-5.7347.keras\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 1s/step - loss: 5.7154\n","Epoch 26/150\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 5.6824\n","Epoch 26: loss improved from 5.73473 to 5.68472, saving model to saved_weights_for_words/saved_weights-26-5.6847.keras\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 1s/step - loss: 5.6824\n","Epoch 27/150\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 5.6451\n","Epoch 27: loss improved from 5.68472 to 5.64781, saving model to saved_weights_for_words/saved_weights-27-5.6478.keras\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 1s/step - loss: 5.6452\n","Epoch 28/150\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 5.5809\n","Epoch 28: loss improved from 5.64781 to 5.60936, saving model to saved_weights_for_words/saved_weights-28-5.6094.keras\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 1s/step - loss: 5.5816\n","Epoch 29/150\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - loss: 5.5488\n","Epoch 29: loss improved from 5.60936 to 5.56813, saving model to saved_weights_for_words/saved_weights-29-5.5681.keras\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 2s/step - loss: 5.5493\n","Epoch 30/150\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 5.5041\n","Epoch 30: loss improved from 5.56813 to 5.53006, saving model to saved_weights_for_words/saved_weights-30-5.5301.keras\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 1s/step - loss: 5.5047\n","Epoch 31/150\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 5.4906\n","Epoch 31: loss improved from 5.53006 to 5.48796, saving model to saved_weights_for_words/saved_weights-31-5.4880.keras\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 1s/step - loss: 5.4905\n","Epoch 32/150\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 5.4696\n","Epoch 32: loss improved from 5.48796 to 5.45030, saving model to saved_weights_for_words/saved_weights-32-5.4503.keras\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 1s/step - loss: 5.4691\n","Epoch 33/150\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 5.3671\n","Epoch 33: loss improved from 5.45030 to 5.41615, saving model to saved_weights_for_words/saved_weights-33-5.4162.keras\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 1s/step - loss: 5.3684\n","Epoch 34/150\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 5.3271\n","Epoch 34: loss improved from 5.41615 to 5.37284, saving model to saved_weights_for_words/saved_weights-34-5.3728.keras\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 1s/step - loss: 5.3283\n","Epoch 35/150\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 5.2977\n","Epoch 35: loss improved from 5.37284 to 5.33826, saving model to saved_weights_for_words/saved_weights-35-5.3383.keras\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 1s/step - loss: 5.2988\n","Epoch 36/150\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 5.2969\n","Epoch 36: loss improved from 5.33826 to 5.29778, saving model to saved_weights_for_words/saved_weights-36-5.2978.keras\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 1s/step - loss: 5.2970\n","Epoch 37/150\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 5.2399\n","Epoch 37: loss improved from 5.29778 to 5.26172, saving model to saved_weights_for_words/saved_weights-37-5.2617.keras\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 1s/step - loss: 5.2405\n","Epoch 38/150\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 5.2153\n","Epoch 38: loss improved from 5.26172 to 5.22742, saving model to saved_weights_for_words/saved_weights-38-5.2274.keras\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 1s/step - loss: 5.2156\n","Epoch 39/150\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 5.1462\n","Epoch 39: loss improved from 5.22742 to 5.18692, saving model to saved_weights_for_words/saved_weights-39-5.1869.keras\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 1s/step - loss: 5.1472\n","Epoch 40/150\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 5.1240\n","Epoch 40: loss improved from 5.18692 to 5.15720, saving model to saved_weights_for_words/saved_weights-40-5.1572.keras\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 1s/step - loss: 5.1249\n","Epoch 41/150\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 5.0965\n","Epoch 41: loss improved from 5.15720 to 5.11995, saving model to saved_weights_for_words/saved_weights-41-5.1199.keras\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 1s/step - loss: 5.0972\n","Epoch 42/150\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 5.0656\n","Epoch 42: loss improved from 5.11995 to 5.08112, saving model to saved_weights_for_words/saved_weights-42-5.0811.keras\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 1s/step - loss: 5.0660\n","Epoch 43/150\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - loss: 5.0212\n","Epoch 43: loss improved from 5.08112 to 5.05484, saving model to saved_weights_for_words/saved_weights-43-5.0548.keras\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 2s/step - loss: 5.0221\n","Epoch 44/150\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 5.0285\n","Epoch 44: loss improved from 5.05484 to 5.01827, saving model to saved_weights_for_words/saved_weights-44-5.0183.keras\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 1s/step - loss: 5.0282\n","Epoch 45/150\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 4.9706\n","Epoch 45: loss improved from 5.01827 to 4.98831, saving model to saved_weights_for_words/saved_weights-45-4.9883.keras\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 1s/step - loss: 4.9711\n","Epoch 46/150\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 4.9331\n","Epoch 46: loss improved from 4.98831 to 4.95266, saving model to saved_weights_for_words/saved_weights-46-4.9527.keras\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 1s/step - loss: 4.9336\n","Epoch 47/150\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 4.8814\n","Epoch 47: loss improved from 4.95266 to 4.91892, saving model to saved_weights_for_words/saved_weights-47-4.9189.keras\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 1s/step - loss: 4.8824\n","Epoch 48/150\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 4.8373\n","Epoch 48: loss improved from 4.91892 to 4.88840, saving model to saved_weights_for_words/saved_weights-48-4.8884.keras\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 1s/step - loss: 4.8387\n","Epoch 49/150\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 4.7936\n","Epoch 49: loss improved from 4.88840 to 4.85904, saving model to saved_weights_for_words/saved_weights-49-4.8590.keras\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 1s/step - loss: 4.7953\n","Epoch 50/150\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 4.8209\n","Epoch 50: loss improved from 4.85904 to 4.82855, saving model to saved_weights_for_words/saved_weights-50-4.8286.keras\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 1s/step - loss: 4.8211\n","Epoch 51/150\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 4.7780\n","Epoch 51: loss improved from 4.82855 to 4.79695, saving model to saved_weights_for_words/saved_weights-51-4.7970.keras\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 1s/step - loss: 4.7785\n","Epoch 52/150\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 4.6687\n","Epoch 52: loss improved from 4.79695 to 4.76202, saving model to saved_weights_for_words/saved_weights-52-4.7620.keras\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 1s/step - loss: 4.6712\n","Epoch 53/150\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 4.6595\n","Epoch 53: loss improved from 4.76202 to 4.73161, saving model to saved_weights_for_words/saved_weights-53-4.7316.keras\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 1s/step - loss: 4.6614\n","Epoch 54/150\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 4.6653\n","Epoch 54: loss improved from 4.73161 to 4.70246, saving model to saved_weights_for_words/saved_weights-54-4.7025.keras\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 1s/step - loss: 4.6663\n","Epoch 55/150\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 4.6399\n","Epoch 55: loss improved from 4.70246 to 4.67924, saving model to saved_weights_for_words/saved_weights-55-4.6792.keras\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 1s/step - loss: 4.6410\n","Epoch 56/150\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 4.6232\n","Epoch 56: loss improved from 4.67924 to 4.64605, saving model to saved_weights_for_words/saved_weights-56-4.6461.keras\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 1s/step - loss: 4.6238\n","Epoch 57/150\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 4.5302\n","Epoch 57: loss improved from 4.64605 to 4.61888, saving model to saved_weights_for_words/saved_weights-57-4.6189.keras\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 1s/step - loss: 4.5325\n","Epoch 58/150\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 4.5735\n","Epoch 58: loss improved from 4.61888 to 4.58933, saving model to saved_weights_for_words/saved_weights-58-4.5893.keras\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 1s/step - loss: 4.5739\n","Epoch 59/150\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 4.5532\n","Epoch 59: loss improved from 4.58933 to 4.56102, saving model to saved_weights_for_words/saved_weights-59-4.5610.keras\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 1s/step - loss: 4.5535\n","Epoch 60/150\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 4.5104\n","Epoch 60: loss improved from 4.56102 to 4.53009, saving model to saved_weights_for_words/saved_weights-60-4.5301.keras\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 1s/step - loss: 4.5110\n","Epoch 61/150\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 4.4812\n","Epoch 61: loss improved from 4.53009 to 4.50062, saving model to saved_weights_for_words/saved_weights-61-4.5006.keras\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 1s/step - loss: 4.4817\n","Epoch 62/150\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 4.4507\n","Epoch 62: loss improved from 4.50062 to 4.47982, saving model to saved_weights_for_words/saved_weights-62-4.4798.keras\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 1s/step - loss: 4.4515\n","Epoch 63/150\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 4.3983\n","Epoch 63: loss improved from 4.47982 to 4.44438, saving model to saved_weights_for_words/saved_weights-63-4.4444.keras\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 1s/step - loss: 4.3995\n","Epoch 64/150\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 4.3755\n","Epoch 64: loss improved from 4.44438 to 4.41566, saving model to saved_weights_for_words/saved_weights-64-4.4157.keras\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 1s/step - loss: 4.3766\n","Epoch 65/150\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 4.3909\n","Epoch 65: loss improved from 4.41566 to 4.39417, saving model to saved_weights_for_words/saved_weights-65-4.3942.keras\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 1s/step - loss: 4.3910\n","Epoch 66/150\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 4.3755\n","Epoch 66: loss improved from 4.39417 to 4.36093, saving model to saved_weights_for_words/saved_weights-66-4.3609.keras\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 1s/step - loss: 4.3751\n","Epoch 67/150\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 4.3332\n","Epoch 67: loss improved from 4.36093 to 4.33756, saving model to saved_weights_for_words/saved_weights-67-4.3376.keras\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 1s/step - loss: 4.3333\n","Epoch 68/150\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 4.2675\n","Epoch 68: loss improved from 4.33756 to 4.30892, saving model to saved_weights_for_words/saved_weights-68-4.3089.keras\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 1s/step - loss: 4.2686\n","Epoch 69/150\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 4.2357\n","Epoch 69: loss improved from 4.30892 to 4.28206, saving model to saved_weights_for_words/saved_weights-69-4.2821.keras\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 1s/step - loss: 4.2369\n","Epoch 70/150\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 4.1627\n","Epoch 70: loss improved from 4.28206 to 4.25327, saving model to saved_weights_for_words/saved_weights-70-4.2533.keras\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 1s/step - loss: 4.1651\n","Epoch 71/150\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 4.1416\n","Epoch 71: loss improved from 4.25327 to 4.23009, saving model to saved_weights_for_words/saved_weights-71-4.2301.keras\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 1s/step - loss: 4.1439\n","Epoch 72/150\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 4.1603\n","Epoch 72: loss improved from 4.23009 to 4.19584, saving model to saved_weights_for_words/saved_weights-72-4.1958.keras\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 1s/step - loss: 4.1612\n","Epoch 73/150\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 4.1683\n","Epoch 73: loss improved from 4.19584 to 4.17342, saving model to saved_weights_for_words/saved_weights-73-4.1734.keras\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 1s/step - loss: 4.1684\n","Epoch 74/150\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 4.1560\n","Epoch 74: loss improved from 4.17342 to 4.14790, saving model to saved_weights_for_words/saved_weights-74-4.1479.keras\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 1s/step - loss: 4.1558\n","Epoch 75/150\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 4.0949\n","Epoch 75: loss improved from 4.14790 to 4.12387, saving model to saved_weights_for_words/saved_weights-75-4.1239.keras\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 1s/step - loss: 4.0957\n","Epoch 76/150\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 4.0243\n","Epoch 76: loss improved from 4.12387 to 4.09708, saving model to saved_weights_for_words/saved_weights-76-4.0971.keras\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 1s/step - loss: 4.0263\n","Epoch 77/150\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 4.0697\n","Epoch 77: loss improved from 4.09708 to 4.06729, saving model to saved_weights_for_words/saved_weights-77-4.0673.keras\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 1s/step - loss: 4.0697\n","Epoch 78/150\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 4.0109\n","Epoch 78: loss improved from 4.06729 to 4.04348, saving model to saved_weights_for_words/saved_weights-78-4.0435.keras\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 1s/step - loss: 4.0117\n","Epoch 79/150\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 4.0333\n","Epoch 79: loss improved from 4.04348 to 4.01628, saving model to saved_weights_for_words/saved_weights-79-4.0163.keras\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 1s/step - loss: 4.0329\n","Epoch 80/150\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 3.9481\n","Epoch 80: loss improved from 4.01628 to 3.98976, saving model to saved_weights_for_words/saved_weights-80-3.9898.keras\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 1s/step - loss: 3.9492\n","Epoch 81/150\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 3.9226\n","Epoch 81: loss improved from 3.98976 to 3.96476, saving model to saved_weights_for_words/saved_weights-81-3.9648.keras\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 1s/step - loss: 3.9237\n","Epoch 82/150\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 3.9664\n","Epoch 82: loss improved from 3.96476 to 3.93858, saving model to saved_weights_for_words/saved_weights-82-3.9386.keras\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 1s/step - loss: 3.9656\n","Epoch 83/150\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 3.8606\n","Epoch 83: loss improved from 3.93858 to 3.91206, saving model to saved_weights_for_words/saved_weights-83-3.9121.keras\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 1s/step - loss: 3.8620\n","Epoch 84/150\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 3.8452\n","Epoch 84: loss improved from 3.91206 to 3.88881, saving model to saved_weights_for_words/saved_weights-84-3.8888.keras\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 1s/step - loss: 3.8464\n","Epoch 85/150\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 3.8336\n","Epoch 85: loss improved from 3.88881 to 3.85917, saving model to saved_weights_for_words/saved_weights-85-3.8592.keras\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 1s/step - loss: 3.8343\n","Epoch 86/150\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 3.8047\n","Epoch 86: loss improved from 3.85917 to 3.83510, saving model to saved_weights_for_words/saved_weights-86-3.8351.keras\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 1s/step - loss: 3.8055\n","Epoch 87/150\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 3.8083\n","Epoch 87: loss improved from 3.83510 to 3.81462, saving model to saved_weights_for_words/saved_weights-87-3.8146.keras\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 1s/step - loss: 3.8085\n","Epoch 88/150\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 3.7218\n","Epoch 88: loss improved from 3.81462 to 3.78716, saving model to saved_weights_for_words/saved_weights-88-3.7872.keras\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 1s/step - loss: 3.7235\n","Epoch 89/150\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 3.7181\n","Epoch 89: loss improved from 3.78716 to 3.76185, saving model to saved_weights_for_words/saved_weights-89-3.7619.keras\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 1s/step - loss: 3.7192\n","Epoch 90/150\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 3.6730\n","Epoch 90: loss improved from 3.76185 to 3.73300, saving model to saved_weights_for_words/saved_weights-90-3.7330.keras\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 1s/step - loss: 3.6746\n","Epoch 91/150\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 3.6849\n","Epoch 91: loss improved from 3.73300 to 3.70315, saving model to saved_weights_for_words/saved_weights-91-3.7032.keras\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 1s/step - loss: 3.6854\n","Epoch 92/150\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 3.7042\n","Epoch 92: loss improved from 3.70315 to 3.68677, saving model to saved_weights_for_words/saved_weights-92-3.6868.keras\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 1s/step - loss: 3.7037\n","Epoch 93/150\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 3.6211\n","Epoch 93: loss improved from 3.68677 to 3.65802, saving model to saved_weights_for_words/saved_weights-93-3.6580.keras\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 1s/step - loss: 3.6221\n","Epoch 94/150\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 3.5816\n","Epoch 94: loss improved from 3.65802 to 3.63924, saving model to saved_weights_for_words/saved_weights-94-3.6392.keras\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 1s/step - loss: 3.5831\n","Epoch 95/150\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 3.6070\n","Epoch 95: loss improved from 3.63924 to 3.60538, saving model to saved_weights_for_words/saved_weights-95-3.6054.keras\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 1s/step - loss: 3.6069\n","Epoch 96/150\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 3.5173\n","Epoch 96: loss improved from 3.60538 to 3.58539, saving model to saved_weights_for_words/saved_weights-96-3.5854.keras\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 1s/step - loss: 3.5191\n","Epoch 97/150\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 3.5490\n","Epoch 97: loss improved from 3.58539 to 3.55615, saving model to saved_weights_for_words/saved_weights-97-3.5561.keras\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 1s/step - loss: 3.5492\n","Epoch 98/150\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 3.4758\n","Epoch 98: loss improved from 3.55615 to 3.53252, saving model to saved_weights_for_words/saved_weights-98-3.5325.keras\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 1s/step - loss: 3.4773\n","Epoch 99/150\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 3.4950\n","Epoch 99: loss improved from 3.53252 to 3.50301, saving model to saved_weights_for_words/saved_weights-99-3.5030.keras\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 1s/step - loss: 3.4952\n","Epoch 100/150\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 3.4505\n","Epoch 100: loss improved from 3.50301 to 3.48229, saving model to saved_weights_for_words/saved_weights-100-3.4823.keras\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 1s/step - loss: 3.4513\n","Epoch 101/150\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 3.4370\n","Epoch 101: loss improved from 3.48229 to 3.45936, saving model to saved_weights_for_words/saved_weights-101-3.4594.keras\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 1s/step - loss: 3.4376\n","Epoch 102/150\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 3.4077\n","Epoch 102: loss improved from 3.45936 to 3.42971, saving model to saved_weights_for_words/saved_weights-102-3.4297.keras\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 1s/step - loss: 3.4083\n","Epoch 103/150\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 3.3958\n","Epoch 103: loss improved from 3.42971 to 3.40975, saving model to saved_weights_for_words/saved_weights-103-3.4097.keras\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 1s/step - loss: 3.3961\n","Epoch 104/150\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 3.3719\n","Epoch 104: loss improved from 3.40975 to 3.38242, saving model to saved_weights_for_words/saved_weights-104-3.3824.keras\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 1s/step - loss: 3.3722\n","Epoch 105/150\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 3.3351\n","Epoch 105: loss improved from 3.38242 to 3.35891, saving model to saved_weights_for_words/saved_weights-105-3.3589.keras\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 1s/step - loss: 3.3358\n","Epoch 106/150\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 3.3010\n","Epoch 106: loss improved from 3.35891 to 3.33093, saving model to saved_weights_for_words/saved_weights-106-3.3309.keras\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 1s/step - loss: 3.3018\n","Epoch 107/150\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 3.2893\n","Epoch 107: loss improved from 3.33093 to 3.30926, saving model to saved_weights_for_words/saved_weights-107-3.3093.keras\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 1s/step - loss: 3.2898\n","Epoch 108/150\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 3.2721\n","Epoch 108: loss improved from 3.30926 to 3.28184, saving model to saved_weights_for_words/saved_weights-108-3.2818.keras\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 1s/step - loss: 3.2723\n","Epoch 109/150\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 3.2388\n","Epoch 109: loss improved from 3.28184 to 3.25678, saving model to saved_weights_for_words/saved_weights-109-3.2568.keras\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 1s/step - loss: 3.2393\n","Epoch 110/150\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 3.1908\n","Epoch 110: loss improved from 3.25678 to 3.23394, saving model to saved_weights_for_words/saved_weights-110-3.2339.keras\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 1s/step - loss: 3.1919\n","Epoch 111/150\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 3.1189\n","Epoch 111: loss improved from 3.23394 to 3.20830, saving model to saved_weights_for_words/saved_weights-111-3.2083.keras\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 1s/step - loss: 3.1212\n","Epoch 112/150\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 3.1774\n","Epoch 112: loss improved from 3.20830 to 3.18065, saving model to saved_weights_for_words/saved_weights-112-3.1807.keras\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 1s/step - loss: 3.1775\n","Epoch 113/150\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 3.1271\n","Epoch 113: loss improved from 3.18065 to 3.15659, saving model to saved_weights_for_words/saved_weights-113-3.1566.keras\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 1s/step - loss: 3.1279\n","Epoch 114/150\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 3.0964\n","Epoch 114: loss improved from 3.15659 to 3.13307, saving model to saved_weights_for_words/saved_weights-114-3.1331.keras\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 1s/step - loss: 3.0974\n","Epoch 115/150\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 3.1253\n","Epoch 115: loss improved from 3.13307 to 3.10873, saving model to saved_weights_for_words/saved_weights-115-3.1087.keras\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 1s/step - loss: 3.1249\n","Epoch 116/150\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 3.0669\n","Epoch 116: loss improved from 3.10873 to 3.08303, saving model to saved_weights_for_words/saved_weights-116-3.0830.keras\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 1s/step - loss: 3.0673\n","Epoch 117/150\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 3.0815\n","Epoch 117: loss improved from 3.08303 to 3.05741, saving model to saved_weights_for_words/saved_weights-117-3.0574.keras\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 1s/step - loss: 3.0808\n","Epoch 118/150\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 3.0050\n","Epoch 118: loss improved from 3.05741 to 3.03726, saving model to saved_weights_for_words/saved_weights-118-3.0373.keras\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 1s/step - loss: 3.0059\n","Epoch 119/150\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 3.0034\n","Epoch 119: loss improved from 3.03726 to 3.00602, saving model to saved_weights_for_words/saved_weights-119-3.0060.keras\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 1s/step - loss: 3.0035\n","Epoch 120/150\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 2.9469\n","Epoch 120: loss improved from 3.00602 to 2.97944, saving model to saved_weights_for_words/saved_weights-120-2.9794.keras\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 1s/step - loss: 2.9478\n","Epoch 121/150\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 2.9481\n","Epoch 121: loss improved from 2.97944 to 2.95767, saving model to saved_weights_for_words/saved_weights-121-2.9577.keras\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 1s/step - loss: 2.9484\n","Epoch 122/150\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 2.8831\n","Epoch 122: loss improved from 2.95767 to 2.93401, saving model to saved_weights_for_words/saved_weights-122-2.9340.keras\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 1s/step - loss: 2.8844\n","Epoch 123/150\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 2.8365\n","Epoch 123: loss improved from 2.93401 to 2.90984, saving model to saved_weights_for_words/saved_weights-123-2.9098.keras\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 1s/step - loss: 2.8384\n","Epoch 124/150\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 2.9066\n","Epoch 124: loss improved from 2.90984 to 2.88187, saving model to saved_weights_for_words/saved_weights-124-2.8819.keras\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 1s/step - loss: 2.9059\n","Epoch 125/150\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 2.8292\n","Epoch 125: loss improved from 2.88187 to 2.86025, saving model to saved_weights_for_words/saved_weights-125-2.8603.keras\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 1s/step - loss: 2.8300\n","Epoch 126/150\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 2.7892\n","Epoch 126: loss improved from 2.86025 to 2.84051, saving model to saved_weights_for_words/saved_weights-126-2.8405.keras\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 1s/step - loss: 2.7905\n","Epoch 127/150\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 2.7808\n","Epoch 127: loss improved from 2.84051 to 2.81136, saving model to saved_weights_for_words/saved_weights-127-2.8114.keras\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 1s/step - loss: 2.7816\n","Epoch 128/150\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 2.7573\n","Epoch 128: loss improved from 2.81136 to 2.79017, saving model to saved_weights_for_words/saved_weights-128-2.7902.keras\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 1s/step - loss: 2.7582\n","Epoch 129/150\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 2.7400\n","Epoch 129: loss improved from 2.79017 to 2.76428, saving model to saved_weights_for_words/saved_weights-129-2.7643.keras\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 1s/step - loss: 2.7407\n","Epoch 130/150\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 2.7031\n","Epoch 130: loss improved from 2.76428 to 2.74401, saving model to saved_weights_for_words/saved_weights-130-2.7440.keras\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 1s/step - loss: 2.7042\n","Epoch 131/150\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 2.7318\n","Epoch 131: loss improved from 2.74401 to 2.71328, saving model to saved_weights_for_words/saved_weights-131-2.7133.keras\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 1s/step - loss: 2.7314\n","Epoch 132/150\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 2.6506\n","Epoch 132: loss improved from 2.71328 to 2.69052, saving model to saved_weights_for_words/saved_weights-132-2.6905.keras\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 1s/step - loss: 2.6517\n","Epoch 133/150\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 2.6252\n","Epoch 133: loss improved from 2.69052 to 2.66250, saving model to saved_weights_for_words/saved_weights-133-2.6625.keras\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 1s/step - loss: 2.6262\n","Epoch 134/150\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 2.6111\n","Epoch 134: loss improved from 2.66250 to 2.63747, saving model to saved_weights_for_words/saved_weights-134-2.6375.keras\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 1s/step - loss: 2.6118\n","Epoch 135/150\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 2.6490\n","Epoch 135: loss improved from 2.63747 to 2.61727, saving model to saved_weights_for_words/saved_weights-135-2.6173.keras\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 1s/step - loss: 2.6482\n","Epoch 136/150\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 2.5443\n","Epoch 136: loss improved from 2.61727 to 2.59118, saving model to saved_weights_for_words/saved_weights-136-2.5912.keras\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 1s/step - loss: 2.5455\n","Epoch 137/150\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 2.5660\n","Epoch 137: loss improved from 2.59118 to 2.57036, saving model to saved_weights_for_words/saved_weights-137-2.5704.keras\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 1s/step - loss: 2.5661\n","Epoch 138/150\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 2.5048\n","Epoch 138: loss improved from 2.57036 to 2.54624, saving model to saved_weights_for_words/saved_weights-138-2.5462.keras\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 1s/step - loss: 2.5059\n","Epoch 139/150\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 2.4982\n","Epoch 139: loss improved from 2.54624 to 2.52239, saving model to saved_weights_for_words/saved_weights-139-2.5224.keras\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 1s/step - loss: 2.4989\n","Epoch 140/150\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 2.4624\n","Epoch 140: loss improved from 2.52239 to 2.49552, saving model to saved_weights_for_words/saved_weights-140-2.4955.keras\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 1s/step - loss: 2.4632\n","Epoch 141/150\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 2.4925\n","Epoch 141: loss improved from 2.49552 to 2.47426, saving model to saved_weights_for_words/saved_weights-141-2.4743.keras\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 1s/step - loss: 2.4920\n","Epoch 142/150\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 2.4162\n","Epoch 142: loss improved from 2.47426 to 2.44985, saving model to saved_weights_for_words/saved_weights-142-2.4499.keras\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 1s/step - loss: 2.4171\n","Epoch 143/150\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 2.3736\n","Epoch 143: loss improved from 2.44985 to 2.42155, saving model to saved_weights_for_words/saved_weights-143-2.4216.keras\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 1s/step - loss: 2.3749\n","Epoch 144/150\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 2.3638\n","Epoch 144: loss improved from 2.42155 to 2.40092, saving model to saved_weights_for_words/saved_weights-144-2.4009.keras\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 1s/step - loss: 2.3647\n","Epoch 145/150\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 2.3373\n","Epoch 145: loss improved from 2.40092 to 2.37536, saving model to saved_weights_for_words/saved_weights-145-2.3754.keras\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 1s/step - loss: 2.3383\n","Epoch 146/150\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 2.3248\n","Epoch 146: loss improved from 2.37536 to 2.34947, saving model to saved_weights_for_words/saved_weights-146-2.3495.keras\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 1s/step - loss: 2.3254\n","Epoch 147/150\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 2.2990\n","Epoch 147: loss improved from 2.34947 to 2.33419, saving model to saved_weights_for_words/saved_weights-147-2.3342.keras\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 1s/step - loss: 2.3000\n","Epoch 148/150\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 2.3147\n","Epoch 148: loss improved from 2.33419 to 2.30054, saving model to saved_weights_for_words/saved_weights-148-2.3005.keras\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 1s/step - loss: 2.3143\n","Epoch 149/150\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 2.2223\n","Epoch 149: loss improved from 2.30054 to 2.27860, saving model to saved_weights_for_words/saved_weights-149-2.2786.keras\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 1s/step - loss: 2.2238\n","Epoch 150/150\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 2.2500\n","Epoch 150: loss improved from 2.27860 to 2.25451, saving model to saved_weights_for_words/saved_weights-150-2.2545.keras\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 1s/step - loss: 2.2501\n"]}],"source":["model.fit([encoder_input_data , decoder_input_data], decoder_output_data, batch_size=50, epochs=150, callbacks=callbacks_list )\n","model.save( 'model.h5' )"]},{"cell_type":"markdown","metadata":{"id":"F1MIy1j9aVTo"},"source":["# Step 6: Defining Inference Models\n","\n","Encoder Inference Model: Takes questions as input and outputs LSTM states (h and c)\n","\n","Decoder Inference Model: Takes in 2 inputs one are the LSTM states, second are the answer input sequences. it will o/p the answers for questions which fed to the encoder model and it's state values."]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2024-06-11T17:08:51.007107Z","iopub.status.busy":"2024-06-11T17:08:51.006672Z","iopub.status.idle":"2024-06-11T17:08:51.015518Z","shell.execute_reply":"2024-06-11T17:08:51.014154Z","shell.execute_reply.started":"2024-06-11T17:08:51.007077Z"},"id":"MpLowS27cn8X","trusted":true},"outputs":[],"source":["def make_inference_models():\n","\n","    encoder_model = tf.keras.models.Model(encoder_inputs, encoder_states)\n","\n","    decoder_state_input_h = tf.keras.layers.Input(shape=( 200 ,))\n","    decoder_state_input_c = tf.keras.layers.Input(shape=( 200 ,))\n","\n","    decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n","\n","    decoder_outputs, state_h, state_c = decoder_lstm(\n","        decoder_embedding , initial_state=decoder_states_inputs)\n","\n","    decoder_states = [state_h, state_c]\n","\n","    decoder_outputs = decoder_dense(decoder_outputs)\n","\n","    decoder_model = tf.keras.models.Model(\n","        [decoder_inputs] + decoder_states_inputs,\n","        [decoder_outputs] + decoder_states)\n","\n","    return encoder_model , decoder_model"]},{"cell_type":"markdown","metadata":{"id":"EwoYVsBTeYra"},"source":["# Step 7: Talking with the Chatbot\n","\n","define a method str_to_tokens which converts str questions to Integer tokens with padding.\n","\n","1. First, we take a question as input and predict the state values using enc_model.\n","2. We set the state values in the decoder's LSTM.\n","3. Then, we generate a sequence which contains the <start> element.\n","4. We input this sequence in the dec_model.\n","5. We replace the <start> element with the element which was predicted by the dec_model and update the state values.\n","6. We carry out the above steps iteratively till we hit the <end> tag or the maximum answer length.\n","\n"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2024-06-11T17:09:01.165666Z","iopub.status.busy":"2024-06-11T17:09:01.165284Z","iopub.status.idle":"2024-06-11T17:09:01.172735Z","shell.execute_reply":"2024-06-11T17:09:01.171508Z","shell.execute_reply.started":"2024-06-11T17:09:01.165639Z"},"id":"oA7Yx45Li3wo","trusted":true},"outputs":[],"source":["def str_to_tokens( sentence : str ):\n","\n","    words = sentence.lower().split()\n","    tokens_list = list()\n","\n","    for word in words:\n","        tokens_list.append( tokenizer.word_index[ word ] )\n","    return preprocessing.sequence.pad_sequences( [tokens_list] , maxlen=maxlen_questions , padding='post')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"execution":{"iopub.execute_input":"2024-06-11T17:15:43.677478Z","iopub.status.busy":"2024-06-11T17:15:43.676925Z"},"id":"eUr4SQDveVb0","outputId":"039a5180-4ebf-4900-95c2-e74eee7a26ee","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Enter question :  የሙዝ ሰብል የመጣው ከየት ነው\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 218ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n"," ደቡብ እስያ end\n"]},{"name":"stdout","output_type":"stream","text":["Enter question :  ማንጎ ለማልማት የበለጠ የትኛው ከፍታ ተስማሚ ነው\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n"," ከባህር ጠለል በላይ ከ 1800 ሜትር end\n"]},{"name":"stdout","output_type":"stream","text":["Enter question :  በነጭ ሚዛን የተጎዳ የማንጎ ተክል ምልክቶች ምንድ ናቸው\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n"," ቅጠሎቹ ቅጠሎቹ አበቦች እና ፍራፍሬዎች ላይ ጥቁር ነጠብጣቦች end\n"]},{"name":"stdout","output_type":"stream","text":["Enter question :  የሙዝ በሽታዎች ምንድን ናቸው\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n"," ማንጎ እስያ እና ተክሉን ያለው ዘይት ዘይት ሰብል ነው። end\n"]}],"source":["enc_model , dec_model = make_inference_models()\n","\n","for _ in range(10):\n","    states_values = enc_model.predict( str_to_tokens( input( 'Enter question : ' ) ) )\n","    empty_target_seq = np.zeros( ( 1 , 1 ) )\n","    empty_target_seq[0, 0] = tokenizer.word_index['start']\n","    stop_condition = False\n","    decoded_translation = ''\n","    while not stop_condition :\n","        dec_outputs , h , c = dec_model.predict([ empty_target_seq ] + states_values )\n","        sampled_word_index = np.argmax( dec_outputs[0, -1, :] )\n","        sampled_word = None\n","        for word , index in tokenizer.word_index.items() :\n","            if sampled_word_index == index :\n","                decoded_translation += ' {}'.format( word )\n","                sampled_word = word\n","\n","        if sampled_word == 'end' or len(decoded_translation.split()) > maxlen_answers:\n","            stop_condition = True\n","\n","        empty_target_seq = np.zeros( ( 1 , 1 ) )\n","        empty_target_seq[ 0 , 0 ] = sampled_word_index\n","        states_values = [ h , c ]\n","\n","    print( decoded_translation )"]},{"cell_type":"markdown","metadata":{"id":"xPNjNwxUl2DO"},"source":["# Conversion to TFLite\n","\n","We can convert our seq2seq model to a TensorFlow Lite model so that we can use it on edge devices\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":891},"id":"Ywh_aJ-Ulxme","outputId":"9744d53e-8655-4d78-bb73-d3b28a65eb95"},"outputs":[],"source":["!pip install tf-nightly"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":33},"id":"Y3C3SlT-mboI","outputId":"3b4f6af1-4a57-4f7e-8c6f-efcc3abc3edd"},"outputs":[],"source":["converter = tf.lite.TFLiteConverter.from_keras_model( enc_model )\n","buffer = converter.convert()\n","open( 'enc_model.tflite' , 'wb' ).write( buffer )\n","\n","converter = tf.lite.TFLiteConverter.from_keras_model( dec_model )\n","open( 'dec_model.tflite' , 'wb' ).write( buffer )"]}],"metadata":{"colab":{"provenance":[]},"kaggle":{"accelerator":"none","dataSources":[{"datasetId":5191166,"sourceId":8663647,"sourceType":"datasetVersion"},{"datasetId":5191474,"sourceId":8664046,"sourceType":"datasetVersion"},{"datasetId":5191822,"sourceId":8664487,"sourceType":"datasetVersion"}],"dockerImageVersionId":30732,"isGpuEnabled":false,"isInternetEnabled":false,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
